 تمرین 9.2.1  این تمرین به بررسی **فاصله کسینوسی** (Cosine Distance) بین بردارهای مشخصه (Feature Vectors) کامپیوترها، با در نظر گرفتن فاکتورهای مقیاس‌بندی مختلف می‌پردازد. فاصله کسینوسی در فضاهایی که دارای ابعاد هستند، از جمله فضاهای اقلیدسی، کاربرد دارد و می‌تواند برای اندازه‌گیری شباهت بین اقلام یا کاربران در سیستم‌های توصیه‌گر استفاده شود.

**تعریف بردارهای مشخصه برای کامپیوترها:**
بر اساس مقادیر داده شده در جدول، بردارهای مشخصه برای هر کامپیوتر به شرح زیر است:
*   **کامپیوتر A**: [سرعت پردازنده: 3.06, حجم دیسک: 500, حجم حافظه اصلی: 6]
*   **کامپیوتر B**: [سرعت پردازنده: 2.68, حجم دیسک: 320, حجم حافظه اصلی: 4]
*   **کامپیوتر C**: [سرعت پردازنده: 2.92, حجم دیسک: 640, حجم حافظه اصلی: 6]

همانطور که در منبع اشاره شده است، اگر این اجزا مقیاس‌بندی نشوند، مولفه‌ی **حجم دیسک** به دلیل مقادیر بسیار بزرگتر خود نسبت به سایر مولفه‌ها، بر محاسبه‌ی شباهت غلبه خواهد کرد. بنابراین، فاکتورهای مقیاس‌بندی برای هر مولفه در نظر گرفته می‌شود:
*   سرعت پردازنده: 1
*   حجم دیسک: $\alpha$
*   حجم حافظه اصلی: $\beta$

بردارهای مقیاس‌بندی شده برای هر کامپیوتر:
*   **A_scaled** = $[3.06 \times 1, 500 \times \alpha, 6 \times \beta] = [3.06, 500\alpha, 6\beta]$
*   **B_scaled** = $[2.68 \times 1, 320 \times \alpha, 4 \times \beta] = [2.68, 320\alpha, 4\beta]$
*   **C_scaled** = $[2.92 \times 1, 640 \times \alpha, 6 \times \beta] = [2.92, 640\alpha, 6\beta]$

**فرمول‌های مورد نیاز:**
برای محاسبه **فاصله کسینوسی** بین دو بردار **x** و **y**، ابتدا **حاصل‌ضرب داخلی** (Dot Product) و **نُرم L2** (L2-norm) هر بردار را محاسبه می‌کنیم:

*   **حاصل‌ضرب داخلی:** $\mathbf{x} \cdot \mathbf{y} = \sum_{i=1}^{n} x_i y_i$
*   **نُرم L2:** $||\mathbf{x}|| = \sqrt{\sum_{i=1}^{n} x_i^2}$
*   **کسینوس زاویه بین دو بردار ($\theta$):** $\cos(\theta) = \frac{\mathbf{x} \cdot \mathbf{y}}{||\mathbf{x}|| \cdot ||\mathbf{y}||}$
*   **زاویه بر حسب درجه:** $\theta = \arccos(\cos(\theta)) \times \frac{180}{\pi}$

---

### **(a) محاسبه کسینوس زوایا بر حسب $\alpha$ و $\beta$:**

**1. برای جفت (A, B):**
*   **حاصل‌ضرب داخلی:**
    $\mathbf{A} \cdot \mathbf{B} = (3.06)(2.68) + (500\alpha)(320\alpha) + (6\beta)(4\beta)$
    $= 8.2008 + 160000\alpha^2 + 24\beta^2$
*   **نُرم A به توان 2:**
    $||\mathbf{A}||^2 = (3.06)^2 + (500\alpha)^2 + (6\beta)^2$
    $= 9.3636 + 250000\alpha^2 + 36\beta^2$
*   **نُرم B به توان 2:**
    $||\mathbf{B}||^2 = (2.68)^2 + (320\alpha)^2 + (4\beta)^2$
    $= 7.1824 + 102400\alpha^2 + 16\beta^2$
*   **کسینوس زاویه (A, B):**
    $\cos(\theta_{AB}) = \frac{8.2008 + 160000\alpha^2 + 24\beta^2}{\sqrt{(9.3636 + 250000\alpha^2 + 36\beta^2) \times (7.1824 + 102400\alpha^2 + 16\beta^2)}}$

**2. برای جفت (A, C):**
*   **حاصل‌ضرب داخلی:**
    $\mathbf{A} \cdot \mathbf{C} = (3.06)(2.92) + (500\alpha)(640\alpha) + (6\beta)(6\beta)$
    $= 8.9352 + 320000\alpha^2 + 36\beta^2$
*   **نُرم A به توان 2:** (همان بالا)
    $||\mathbf{A}||^2 = 9.3636 + 250000\alpha^2 + 36\beta^2$
*   **نُرم C به توان 2:**
    $||\mathbf{C}||^2 = (2.92)^2 + (640\alpha)^2 + (6\beta)^2$
    $= 8.5264 + 409600\alpha^2 + 36\beta^2$
*   **کسینوس زاویه (A, C):**
    $\cos(\theta_{AC}) = \frac{8.9352 + 320000\alpha^2 + 36\beta^2}{\sqrt{(9.3636 + 250000\alpha^2 + 36\beta^2) \times (8.5264 + 409600\alpha^2 + 36\beta^2)}}$

**3. برای جفت (B, C):**
*   **حاصل‌ضرب داخلی:**
    $\mathbf{B} \cdot \mathbf{C} = (2.68)(2.92) + (320\alpha)(640\alpha) + (4\beta)(6\beta)$
    $= 7.8256 + 204800\alpha^2 + 24\beta^2$
*   **نُرم B به توان 2:** (همان بالا)
    $||\mathbf{B}||^2 = 7.1824 + 102400\alpha^2 + 16\beta^2$
*   **نُرم C به توان 2:** (همان بالا)
    $||\mathbf{C}||^2 = 8.5264 + 409600\alpha^2 + 36\beta^2$
*   **کسینوس زاویه (B, C):**
    $\cos(\theta_{BC}) = \frac{7.8256 + 204800\alpha^2 + 24\beta^2}{\sqrt{(7.1824 + 102400\alpha^2 + 16\beta^2) \times (8.5264 + 409600\alpha^2 + 36\beta^2)}}$

---

### **(b) محاسبه زوایا اگر $\alpha = 1$ و $\beta = 1$:**

در این حالت، هیچ مقیاس‌بندی اعمال نمی‌شود و انتظار می‌رود که مولفه‌ی حجم دیسک (با مقادیر 500, 320, 640) بر محاسبات غلبه کند و منجر به زوایای بسیار کوچک (شباهت بالا) شود، حتی اگر در واقعیت کامپیوترها تفاوت‌های قابل توجهی داشته باشند.

**بردارهای مقیاس‌بندی شده:**
*   A_scaled = $[3.06, 500, 6]$
*   B_scaled = $[2.68, 320, 4]$
*   C_scaled = $[2.92, 640, 6]$

**1. برای جفت (A, B):**
*   $\mathbf{A} \cdot \mathbf{B} = 8.2008 + 160000 + 24 = 160032.2008$
*   $||\mathbf{A}|| = \sqrt{9.3636 + 250000 + 36} = \sqrt{250045.3636} \approx 500.045$
*   $||\mathbf{B}|| = \sqrt{7.1824 + 102400 + 16} = \sqrt{102423.1824} \approx 320.036$
*   $\cos(\theta_{AB}) = \frac{160032.2008}{500.045 \times 320.036} = \frac{160032.2008}{160033.911} \approx \mathbf{0.999989}$
*   $\theta_{AB} = \arccos(0.999989) \approx \mathbf{0.25 \text{ degrees}}$

**2. برای جفت (A, C):**
*   $\mathbf{A} \cdot \mathbf{C} = 8.9352 + 320000 + 36 = 320044.9352$
*   $||\mathbf{A}|| \approx 500.045$
*   $||\mathbf{C}|| = \sqrt{8.5264 + 409600 + 36} = \sqrt{409654.5264} \approx 640.042$
*   $\cos(\theta_{AC}) = \frac{320044.9352}{500.045 \times 640.042} = \frac{320044.9352}{320046.225} \approx \mathbf{0.9999959}$
*   $\theta_{AC} = \arccos(0.9999959) \approx \mathbf{0.17 \text{ degrees}}$

**3. برای جفت (B, C):**
*   $\mathbf{B} \cdot \mathbf{C} = 7.8256 + 204800 + 24 = 204831.8256$
*   $||\mathbf{B}|| \approx 320.036$
*   $||\mathbf{C}|| \approx 640.042$
*   $\cos(\theta_{BC}) = \frac{204831.8256}{320.036 \times 640.042} = \frac{204831.8256}{204832.88} \approx \mathbf{0.9999948}$
*   $\theta_{BC} = \arccos(0.9999948) \approx \mathbf{0.21 \text{ degrees}}$

**نتیجه‌گیری برای (b):**
همانطور که مشاهده می‌شود، بدون مقیاس‌بندی مناسب، تمام کسینوس‌های زاویه بسیار نزدیک به 1 و زوایا بسیار کوچک (نزدیک به 0 درجه) هستند. این نشان می‌دهد که تمامی کامپیوترها بسیار شبیه به هم به نظر می‌رسند، که به دلیل غلبه‌ی مولفه‌ی حجم دیسک در محاسبه‌ی نُرم و حاصل‌ضرب داخلی است.

---

### **(c) محاسبه زوایا اگر $\alpha = 0.01$ و $\beta = 0.5$:**

با اعمال این فاکتورهای مقیاس‌بندی، انتظار می‌رود که تأثیر مولفه‌های مختلف در محاسبه‌ی شباهت متعادل‌تر شود و تفاوت‌های واقعی بین کامپیوترها منعکس گردد.

**بردارهای مقیاس‌بندی شده:**
*   A_scaled = $[3.06, 500 \times 0.01, 6 \times 0.5] = [3.06, 5, 3]$
*   B_scaled = $[2.68, 320 \times 0.01, 4 \times 0.5] = [2.68, 3.2, 2]$
*   C_scaled = $[2.92, 640 \times 0.01, 6 \times 0.5] = [2.92, 6.4, 3]$

**1. برای جفت (A, B):**
*   $\mathbf{A} \cdot \mathbf{B} = (3.06)(2.68) + (5)(3.2) + (3)(2) = 8.2008 + 16 + 6 = 30.2008$
*   $||\mathbf{A}|| = \sqrt{(3.06)^2 + 5^2 + 3^2} = \sqrt{9.3636 + 25 + 9} = \sqrt{43.3636} \approx 6.585$
*   $||\mathbf{B}|| = \sqrt{(2.68)^2 + (3.2)^2 + 2^2} = \sqrt{7.1824 + 10.24 + 4} = \sqrt{21.4224} \approx 4.629$
*   $\cos(\theta_{AB}) = \frac{30.2008}{6.585 \times 4.629} = \frac{30.2008}{30.505} \approx \mathbf{0.990}$
*   $\theta_{AB} = \arccos(0.990) \approx \mathbf{8.11 \text{ degrees}}$

**2. برای جفت (A, C):**
*   $\mathbf{A} \cdot \mathbf{C} = (3.06)(2.92) + (5)(6.4) + (3)(3) = 8.9352 + 32 + 9 = 49.9352$
*   $||\mathbf{A}|| \approx 6.585$
*   $||\mathbf{C}|| = \sqrt{(2.92)^2 + (6.4)^2 + 3^2} = \sqrt{8.5264 + 40.96 + 9} = \sqrt{58.4864} \approx 7.648$
*   $\cos(\theta_{AC}) = \frac{49.9352}{6.585 \times 7.648} = \frac{49.9352}{50.407} \approx \mathbf{0.9906}$
*   $\theta_{AC} = \arccos(0.9906) \approx \mathbf{7.78 \text{ degrees}}$

**3. برای جفت (B, C):**
*   $\mathbf{B} \cdot \mathbf{C} = (2.68)(2.92) + (3.2)(6.4) + (2)(3) = 7.8256 + 20.48 + 6 = 34.3056$
*   $||\mathbf{B}|| \approx 4.629$
*   $||\mathbf{C}|| \approx 7.648$
*   $\cos(\theta_{BC}) = \frac{34.3056}{4.629 \times 7.648} = \frac{34.3056}{35.405} \approx \mathbf{0.9689}$
*   $\theta_{BC} = \arccos(0.9689) \approx \mathbf{14.39 \text{ degrees}}$

**نتیجه‌گیری برای (c):**
با اعمال فاکتورهای مقیاس‌بندی $\alpha = 0.01$ و $\beta = 0.5$، زوایا بزرگتر شده‌اند و تفاوت‌های بیشتری را بین جفت‌های کامپیوترها نشان می‌دهند. این امر منعکس‌کننده‌ی تأثیر متعادل‌تر هر مولفه‌ی مشخصه بر روی محاسبه‌ی شباهت است، به طوری که هیچ مولفه‌ای به تنهایی بر نتیجه غلبه نمی‌کند. این نشان می‌دهد که کامپیوترهای A و C (حدود 7.78 درجه) کمی شبیه‌تر از A و B (حدود 8.11 درجه) هستند، و B و C (حدود 14.39 درجه) کمترین شباهت را در بین این سه جفت دارند.



تمرین 9.3.1: شکل 9.8 یک ماتریس امتیازدهی است که نشان‌دهنده امتیازهای کاربران A، B و C به آیتم‌های a تا h بر اساس مقیاس 1-5 است. از داده‌های این ماتریس، مراحل زیر را انجام دهید:
(a) ماتریس امتیازدهی را به صورت بولی تبدیل کنید، سپس فاصله جاکارد بین هر جفت کاربر را محاسبه کنید.

(b) بخش (a) را تکرار کنید، اما این بار از فاصله کسینوسی استفاده کنید.

(c) امتیازهای 3، 4 و 5 را به عنوان 1 و امتیازهای 1 و 2 را به عنوان 0 در نظر بگیرید و فاصله جاکارد بین هر جفت کاربر را محاسبه کنید.

(d) بخش (c) را تکرار کنید، اما این بار از فاصله کسینوسی استفاده کنید.

(e) ماتریس نرمال‌شده را با کسر میانگین از هر مقدار غیرصفر به دست آورید.

(f) از ماتریس به‌دست‌آمده در بخش (e)، فاصله کسینوسی بین هر جفت کاربر را محاسبه کنید


| کاربر/آیتم | a | b | c | d | e | f | g | h |
|:----------|:--|:--|:--|:--|:--|:--|:--|:--|
| **A** | 4 | 5 | 0 | 5 | 1 | 0 | 3 | 2 |
| **B** | 0 | 3 | 4 | 3 | 1 | 2 | 1 | 0 |
| **C** | 2 | 0 | 1 | 3 | 0 | 4 | 5 | 3 |

نکته مهم این است که در ماتریس‌های سودمندی، "صفر" معمولاً به معنای رتبه‌بندی نشده (خالی) یا عدم ترجیح است. با توجه به متن تمرینات در منبع که به "blank" اشاره می‌کند، مقادیر صفر در ماتریس شما (مانند C=0 یا F=0 برای کاربر A) را برای قسمت‌های (الف) و (ب) به عنوان **خالی (Unrated)** در نظر می‌گیرم. اما برای قسمت‌های (ج) و (د) که قانون خاصی برای تبدیل رتبه‌ها به صفر و یک ارائه شده، طبق آن قانون عمل خواهم کرد.

---

### حل تمرین 9.3.1

**ماتریس سودمندی اولیه (با در نظر گرفتن 0 به عنوان خانه خالی):**

| کاربر/آیتم | a | b | c | d | e | f | g | h |
|:----------|:--|:--|:--|:--|:--|:--|:--|:--|
| **A** | 4 | 5 | - | 5 | 1 | - | 3 | 2 |
| **B** | - | 3 | 4 | 3 | 1 | 2 | 1 | - |
| **C** | 2 | - | 1 | 3 | - | 4 | 5 | 3 |

---

**(a) محاسبه فاصله ژاکارد بین هر جفت کاربر، با فرض ماتریس سودمندی به صورت بولی:**

ابتدا ماتریس را به صورت بولی (1 برای آیتم رتبه‌بندی شده، 0 برای آیتم رتبه‌بندی نشده) تبدیل می‌کنیم.

| کاربر/آیتم | a | b | c | d | e | f | g | h |
|:----------|:--|:--|:--|:--|:--|:--|:--|:--|
| **A** | 1 | 1 | 0 | 1 | 1 | 0 | 1 | 1 |
| **B** | 0 | 1 | 1 | 1 | 1 | 1 | 1 | 0 |
| **C** | 1 | 0 | 1 | 1 | 0 | 1 | 1 | 1 |

*   **کاربران A و B:**
    *   آیتم‌های رتبه‌بندی شده توسط A (مجموعه $C_A$): {a, b, d, e, g, h}
    *   آیتم‌های رتبه‌بندی شده توسط B (مجموعه $C_B$): {b, c, d, e, f, g}
    *   اشتراک $C_A \cap C_B$: {b, d, e, g} (اندازه = 4)
    *   اجتماع $C_A \cup C_B$: {a, b, c, d, e, f, g, h} (اندازه = 8)
    *   شباهت ژاکارد $sim(A,B) = |C_A \cap C_B| / |C_A \cup C_B| = 4/8 = 0.5$.
    *   **فاصله ژاکارد $d(A,B) = 1 - sim(A,B) = 1 - 0.5 = 0.5$**.

*   **کاربران A و C:**
    *   آیتم‌های رتبه‌بندی شده توسط A ($C_A$): {a, b, d, e, g, h}
    *   آیتم‌های رتبه‌بندی شده توسط C ($C_C$): {a, c, d, f, g, h}
    *   اشتراک $C_A \cap C_C$: {a, d, g, h} (اندازه = 4)
    *   اجتماع $C_A \cup C_C$: {a, b, c, d, e, f, g, h} (اندازه = 8)
    *   شباهت ژاکارد $sim(A,C) = 4/8 = 0.5$.
    *   **فاصله ژاکارد $d(A,C) = 1 - 0.5 = 0.5$**.

*   **کاربران B و C:**
    *   آیتم‌های رتبه‌بندی شده توسط B ($C_B$): {b, c, d, e, f, g}
    *   آیتم‌های رتبه‌بندی شده توسط C ($C_C$): {a, c, d, f, g, h}
    *   اشتراک $C_B \cap C_C$: {c, d, f, g} (اندازه = 4)
    *   اجتماع $C_B \cup C_C$: {a, b, c, d, e, f, g, h} (اندازه = 8)
    *   شباهت ژاکارد $sim(B,C) = 4/8 = 0.5$.
    *   **فاصله ژاکارد $d(B,C) = 1 - 0.5 = 0.5$**.

---

**(b) تکرار قسمت (الف) با استفاده از فاصله کسینوسی:**

برای محاسبه فاصله کسینوسی، بردارهای بولی کامل (با 0 برای آیتم‌های رتبه‌بندی نشده) استفاده می‌شوند. شباهت کسینوسی برابر است با حاصل ضرب داخلی دو بردار تقسیم بر حاصل ضرب اندازه (نرم) آن‌ها. فاصله کسینوسی برابر با $1 - \text{شباهت کسینوسی}$.

*   **کاربران A و B:**
    *   $V_A =$
    *   $V_B =$
    *   حاصل ضرب داخلی $V_A \cdot V_B = 4$.
    *   اندازه $||V_A|| = \sqrt{1^2+1^2+0^2+1^2+1^2+0^2+1^2+1^2} = \sqrt{6}$.
    *   اندازه $||V_B|| = \sqrt{0^2+1^2+1^2+1^2+1^2+1^2+1^2+0^2} = \sqrt{6}$.
    *   شباهت کسینوسی $sim(A,B) = \frac{4}{\sqrt{6} \cdot \sqrt{6}} = \frac{4}{6} \approx 0.6667$.
    *   **فاصله کسینوسی $d(A,B) = 1 - 0.6667 = 0.3333$**.

*   **کاربران A و C:**
    *   $V_A =$
    *   $V_C =$
    *   حاصل ضرب داخلی $V_A \cdot V_C = 4$.
    *   اندازه $||V_A|| = \sqrt{6}$.
    *   اندازه $||V_C|| = \sqrt{6}$.
    *   شباهت کسینوسی $sim(A,C) = \frac{4}{\sqrt{6} \cdot \sqrt{6}} = \frac{4}{6} \approx 0.6667$.
    *   **فاصله کسینوسی $d(A,C) = 1 - 0.6667 = 0.3333$**.

*   **کاربران B و C:**
    *   $V_B =$
    *   $V_C =$
    *   حاصل ضرب داخلی $V_B \cdot V_C = 4$.
    *   اندازه $||V_B|| = \sqrt{6}$.
    *   اندازه $||V_C|| = \sqrt{6}$.
    *   شباهت کسینوسی $sim(B,C) = \frac{4}{\sqrt{6} \cdot \sqrt{6}} = \frac{4}{6} \approx 0.6667$.
    *   **فاصله کسینوسی $d(B,C) = 1 - 0.6667 = 0.3333$**.

---

**(c) رتبه‌بندی‌های 3، 4، و 5 را 1 و 1، 2، و خانه‌های خالی را 0 در نظر بگیرید. فاصله ژاکارد را بین هر جفت کاربر محاسبه کنید.**

ماتریس بولی جدید (بر اساس مقدار رتبه‌بندی):

| کاربر/آیتم | a | b | c | d | e | f | g | h |
|:----------|:--|:--|:--|:--|:--|:--|:--|:--|
| **A** | 1 (4) | 1 (5) | 0 (0) | 1 (5) | 0 (1) | 0 (0) | 1 (3) | 0 (2) |
| **B** | 0 (0) | 1 (3) | 1 (4) | 1 (3) | 0 (1) | 0 (2) | 0 (1) | 0 (0) |
| **C** | 0 (2) | 0 (0) | 0 (1) | 1 (3) | 0 (0) | 1 (4) | 1 (5) | 1 (3) |

*   **کاربران A و B:**
    *   آیتم‌های دارای 1 برای A ($S_A$): {a, b, d, g}
    *   آیتم‌های دارای 1 برای B ($S_B$): {b, c, d}
    *   اشتراک $S_A \cap S_B$: {b, d} (اندازه = 2)
    *   اجتماع $S_A \cup S_B$: {a, b, c, d, g} (اندازه = 5)
    *   شباهت ژاکارد $sim(A,B) = 2/5 = 0.4$.
    *   **فاصله ژاکارد $d(A,B) = 1 - 0.4 = 0.6$**.

*   **کاربران A و C:**
    *   آیتم‌های دارای 1 برای A ($S_A$): {a, b, d, g}
    *   آیتم‌های دارای 1 برای C ($S_C$): {d, f, g, h}
    *   اشتراک $S_A \cap S_C$: {d, g} (اندازه = 2)
    *   اجتماع $S_A \cup S_C$: {a, b, d, f, g, h} (اندازه = 6)
    *   شباهت ژاکارد $sim(A,C) = 2/6 \approx 0.3333$.
    *   **فاصله ژاکارد $d(A,C) = 1 - 0.3333 = 0.6667$**.

*   **کاربران B و C:**
    *   آیتم‌های دارای 1 برای B ($S_B$): {b, c, d}
    *   آیتم‌های دارای 1 برای C ($S_C$): {d, f, g, h}
    *   اشتراک $S_B \cap S_C$: {d} (اندازه = 1)
    *   اجتماع $S_B \cup S_C$: {b, c, d, f, g, h} (اندازه = 6)
    *   شباهت ژاکارد $sim(B,C) = 1/6 \approx 0.1667$.
    *   **فاصله ژاکارد $d(B,C) = 1 - 0.1667 = 0.8333$**.

---

**(d) تکرار قسمت (ج) با استفاده از فاصله کسینوسی:**

بردارهای بولی جدید (با 0 به عنوان مولفه صریح):

| کاربر/آیتم | a | b | c | d | e | f | g | h |
|:----------|:--|:--|:--|:--|:--|:--|:--|:--|
| **A** | 1 | 1 | 0 | 1 | 0 | 0 | 1 | 0 |
| **B** | 0 | 1 | 1 | 1 | 0 | 0 | 0 | 0 |
| **C** | 0 | 0 | 0 | 1 | 0 | 1 | 1 | 1 |

*   **کاربران A و B:**
    *   $V_A' =$
    *   $V_B' =$
    *   حاصل ضرب داخلی $V_A' \cdot V_B' = (1*0) + (1*1) + (0*1) + (1*1) + (0*0) + (0*0) + (1*0) + (0*0) = 2$.
    *   اندازه $||V_A'|| = \sqrt{1^2+1^2+0^2+1^2+0^2+0^2+1^2+0^2} = \sqrt{4} = 2$.
    *   اندازه $||V_B'|| = \sqrt{0^2+1^2+1^2+1^2+0^2+0^2+0^2+0^2} = \sqrt{3} \approx 1.732$.
    *   شباهت کسینوسی $sim(A,B) = \frac{2}{2 \cdot 1.732} = \frac{2}{3.464} \approx 0.5774$.
    *   **فاصله کسینوسی $d(A,B) = 1 - 0.5774 = 0.4226$**.

*   **کاربران A و C:**
    *   $V_A' =$
    *   $V_C' =$
    *   حاصل ضرب داخلی $V_A' \cdot V_C' = (1*0) + (1*0) + (0*0) + (1*1) + (0*0) + (0*1) + (1*1) + (0*1) = 2$.
    *   اندازه $||V_A'|| = 2$.
    *   اندازه $||V_C'|| = \sqrt{0^2+0^2+0^2+1^2+0^2+1^2+1^2+1^2} = \sqrt{4} = 2$.
    *   شباهت کسینوسی $sim(A,C) = \frac{2}{2 \cdot 2} = \frac{2}{4} = 0.5$.
    *   **فاصله کسینوسی $d(A,C) = 1 - 0.5 = 0.5$**.

*   **کاربران B و C:**
    *   $V_B' =$
    *   $V_C' =$
    *   حاصل ضرب داخلی $V_B' \cdot V_C' = (0*0) + (1*0) + (1*0) + (1*1) + (0*0) + (0*1) + (0*1) + (0*1) = 1$.
    *   اندازه $||V_B'|| = \sqrt{3}$.
    *   اندازه $||V_C'|| = 2$.
    *   شباهت کسینوسی $sim(B,C) = \frac{1}{\sqrt{3} \cdot 2} = \frac{1}{3.464} \approx 0.2887$.
    *   **فاصله کسینوسی $d(B,C) = 1 - 0.2887 = 0.7113$**.

---

**(e) نرمال‌سازی ماتریس با کسر میانگین امتیاز هر کاربر از هر ورودی غیرخالی آن کاربر:**

میانگین رتبه‌بندی‌های هر کاربر (فقط آیتم‌های رتبه‌بندی شده):
*   **کاربر A:** رتبه‌ها: {4, 5, 5, 1, 3, 2}. مجموع = 20. تعداد = 6. میانگین = $20/6 \approx 3.333$.
*   **کاربر B:** رتبه‌ها: {3, 4, 3, 1, 2, 1}. مجموع = 14. تعداد = 6. میانگین = $14/6 \approx 2.333$.
*   **کاربر C:** رتبه‌ها: {2, 1, 3, 4, 5, 3}. مجموع = 18. تعداد = 6. میانگین = $18/6 = 3.0$.

**ماتریس نرمال‌سازی شده (مقدار اصلی - میانگین کاربر):**

| کاربر/آیتم | a | b | c | d | e | f | g | h |
|:----------|:--|:--|:--|:--|:--|:--|:--|:--|
| **A** | $4-3.333=\mathbf{0.667}$ | $5-3.333=\mathbf{1.667}$ | - | $5-3.333=\mathbf{1.667}$ | $1-3.333=\mathbf{-2.333}$ | - | $3-3.333=\mathbf{-0.333}$ | $2-3.333=\mathbf{-1.333}$ |
| **B** | - | $3-2.333=\mathbf{0.667}$ | $4-2.333=\mathbf{1.667}$ | $3-2.333=\mathbf{0.667}$ | $1-2.333=\mathbf{-1.333}$ | $2-2.333=\mathbf{-0.333}$ | $1-2.333=\mathbf{-1.333}$ | - |
| **C** | $2-3.0=\mathbf{-1.0}$ | - | $1-3.0=\mathbf{-2.0}$ | $3-3.0=\mathbf{0.0}$ | - | $4-3.0=\mathbf{1.0}$ | $5-3.0=\mathbf{2.0}$ | $3-3.0=\mathbf{0.0}$ |

---

**(f) با استفاده از ماتریس نرمال‌شده از قسمت (ه)، فاصله کسینوسی را بین هر جفت کاربر محاسبه کنید.**

فقط آیتم‌هایی که توسط هر دو کاربر در یک جفت رتبه‌بندی شده‌اند (غیر خالی هستند) در نظر گرفته می‌شوند.

*   **کاربران A و B:** آیتم‌های مشترک رتبه‌بندی شده: {b, d, e, g}
    *   بردارهای مشترک: $V_A'' = [1.667, 1.667, -2.333, -0.333]$ و $V_B'' = [0.667, 0.667, -1.333, -1.333]$
    *   حاصل ضرب داخلی $V_A'' \cdot V_B'' = (1.667 \times 0.667) + (1.667 \times 0.667) + (-2.333 \times -1.333) + (-0.333 \times -1.333) \approx 1.1115 + 1.1115 + 3.1099 + 0.4435 = 5.7764$.
    *   اندازه $||V_A''|| = \sqrt{1.667^2+1.667^2+(-2.333)^2+(-0.333)^2} = \sqrt{2.7789+2.7789+5.4429+0.1109} = \sqrt{11.1116} \approx 3.333$.
    *   اندازه $||V_B''|| = \sqrt{0.667^2+0.667^2+(-1.333)^2+(-1.333)^2} = \sqrt{0.4449+0.4449+1.7769+1.7769} = \sqrt{4.4436} \approx 2.108$.
    *   شباهت کسینوسی $sim(A,B) = \frac{5.7764}{3.333 \cdot 2.108} \approx \frac{5.7764}{7.026} \approx 0.8222$.
    *   **فاصله کسینوسی $d(A,B) = 1 - 0.8222 = 0.1778$**.

*   **کاربران A و C:** آیتم‌های مشترک رتبه‌بندی شده: {a, d, g, h}
    *   بردارهای مشترک: $V_A'' = [0.667, 1.667, -0.333, -1.333]$ و $V_C'' = [-1.0, 0.0, 2.0, 0.0]$
    *   حاصل ضرب داخلی $V_A'' \cdot V_C'' = (0.667 \times -1.0) + (1.667 \times 0.0) + (-0.333 \times 2.0) + (-1.333 \times 0.0) \approx -0.667 + 0.0 - 0.666 + 0.0 = -1.333$.
    *   اندازه $||V_A''|| = \sqrt{0.667^2+1.667^2+(-0.333)^2+(-1.333)^2} = \sqrt{0.4449+2.7789+0.1109+1.7769} = \sqrt{5.1116} \approx 2.261$.
    *   اندازه $||V_C''|| = \sqrt{(-1.0)^2+0.0^2+2.0^2+0.0^2} = \sqrt{1.0+0.0+4.0+0.0} = \sqrt{5.0} \approx 2.236$.
    *   شباهت کسینوسی $sim(A,C) = \frac{-1.333}{2.261 \cdot 2.236} \approx \frac{-1.333}{5.056} \approx -0.2636$.
    *   **فاصله کسینوسی $d(A,C) = 1 - (-0.2636) = 1.2636$**.

*   **کاربران B و C:** آیتم‌های مشترک رتبه‌بندی شده: {c, d, f, g}
    *   بردارهای مشترک: $V_B'' = [1.667, 0.667, -0.333, -1.333]$ و $V_C'' = [-2.0, 0.0, 1.0, 2.0]$
    *   حاصل ضرب داخلی $V_B'' \cdot V_C'' = (1.667 \times -2.0) + (0.667 \times 0.0) + (-0.333 \times 1.0) + (-1.333 \times 2.0) \approx -3.334 + 0.0 - 0.333 - 2.666 = -6.333$.
    *   اندازه $||V_B''|| = \sqrt{1.667^2+0.667^2+(-0.333)^2+(-1.333)^2} = \sqrt{2.7789+0.4449+0.1109+1.7769} = \sqrt{5.1116} \approx 2.261$.
    *   اندازه $||V_C''|| = \sqrt{(-2.0)^2+0.0^2+1.0^2+2.0^2} = \sqrt{4.0+0.0+1.0+4.0} = \sqrt{9.0} = 3.0$.
    *   شباهت کسینوسی $sim(B,C) = \frac{-6.333}{2.261 \cdot 3.0} \approx \frac{-6.333}{6.783} \approx -0.9337$.
    *   **فاصله کسینوسی $d(B,C) = 1 - (-0.9337) = 1.9337$**.

---


**ترجمه تمرین 9.3.2:**
در این تمرین، آیتم‌های موجود در ماتریس شکل 9.8 را خوشه‌بندی می‌کنیم. مراحل زیر را انجام دهید:

(الف) هشت آیتم را به صورت سلسله‌مراتبی به چهار خوشه خوشه‌بندی کنید. روش خوشه‌بندی باید به این صورت باشد: همه امتیازات 3، 4 و 5 را با 1 و امتیازات 1، 2 و خانه‌های خالی را با 0 جایگزین کنید. از فاصله جاکارد برای اندازه‌گیری فاصله بین بردارهای ستونی حاصل استفاده کنید. برای خوشه‌هایی با بیش از یک عنصر، فاصله بین خوشه‌ها را حداقل فاصله بین جفت عناصر، یکی از هر خوشه، در نظر بگیرید.

(ب) سپس، از ماتریس اصلی شکل 9.8، یک ماتریس جدید بسازید که ردیف‌های آن مانند قبل مربوط به کاربران و ستون‌های آن مربوط به خوشه‌ها باشند. مقدار هر ورودی برای یک کاربر و یک خوشه از آیتم‌ها را با میانگین‌گیری از ورودی‌های غیرخالی برای آن کاربر و همه آیتم‌های آن خوشه محاسبه کنید.

(ج) فاصله کسینوسی بین هر جفت کاربر را با استفاده از ماتریس حاصل از بخش (ب) محاسبه کنید.

**داده‌های ماتریس شکل 9.8**:
(خالی به معنای امتیازدهی نشده است)
| آیتم | a | b | c | d | e | f | g | h |
|------|---|---|---|---|---|---|---|---|
| کاربر A | 4 | 5 |   | 5 | 1 |   | 3 | 2 |
| کاربر B |   | 3 | 4 | 3 | 1 | 2 | 1 |   |
| کاربر C | 2 |   | 1 | 3 |   | 4 | 5 | 3 |

---

**پاسخ به تمرین:**

**بخش (الف): خوشه‌بندی سلسله‌مراتبی آیتم‌ها**

**مرحله 1: تبدیل ماتریس امتیازات به مقادیر دودویی**
امتیازات 3، 4، و 5 به 1 تبدیل می‌شوند و امتیازات 1، 2، و خانه‌های خالی به 0 تبدیل می‌شوند.

| آیتم | a | b | c | d | e | f | g | h |
|------|---|---|---|---|---|---|---|---|
| کاربر A | 1 | 1 | 0 | 1 | 0 | 0 | 1 | 0 |
| کاربر B | 0 | 1 | 1 | 1 | 0 | 0 | 0 | 0 |
| کاربر C | 0 | 0 | 0 | 1 | 0 | 1 | 1 | 1 |

اکنون، هر ستون (آیتم) را به عنوان یک مجموعه دودویی در نظر می‌گیریم. به عنوان مثال، مجموعه آیتم 'a' برای کاربران [A, B, C] به صورت {A} (چون A=1 و B=0 و C=0) نمایش داده می‌شود.

*   Ca = {A}
*   Cb = {A, B}
*   Cc = {B}
*   Cd = {A, B, C}
*   Ce = {}
*   Cf = {C}
*   Cg = {A, C}
*   Ch = {C}

**مرحله 2: محاسبه فاصله جاکارد بین تمام جفت آیتم‌ها**
فاصله جاکارد (d) برابر است با 1 منهای شباهت جاکارد (sim).
شباهت جاکارد بین دو مجموعه S1 و S2 به صورت |S1 ∩ S2| / |S1 ∪ S2| تعریف می‌شود.

برخی از فواصل کلیدی (کوچک‌ترین‌ها در ابتدا):
*   d(Cf, Ch) = 1 - |{C}| / |{C}| = 1 - 1/1 = **0**
*   d(Cb, Cd) = 1 - |{A,B}| / |{A,B,C}| = 1 - 2/3 = **0.333**
*   d(Cd, Cg) = 1 - |{A,C}| / |{A,B,C}| = 1 - 2/3 = **0.333**
*   d(Ca, Cb) = 1 - |{A}| / |{A,B}| = 1 - 1/2 = **0.5**
*   d(Ca, Cg) = 1 - |{A}| / |{A,C}| = 1 - 1/2 = **0.5**
*   d(Cb, Cc) = 1 - |{B}| / |{A,B}| = 1 - 1/2 = **0.5**
*   d(Cf, Cg) = 1 - |{C}| / |{A,C}| = 1 - 1/2 = **0.5**
*   d(Cg, Ch) = 1 - |{C}| / |{A,C}| = 1 - 1/2 = **0.5**
*   d(Cc, Ce) = 1 - |{}| / |{B}| = 1 - 0/1 = **1** (و سایر مواردی که اشتراک صفر و اجتماع غیرصفر دارند)

**مرحله 3: خوشه‌بندی سلسله‌مراتبی (Single-linkage)**
ما با 8 خوشه شروع می‌کنیم و در هر مرحله نزدیکترین جفت خوشه‌ها را ادغام می‌کنیم تا به 4 خوشه برسیم. فاصله بین خوشه‌ها (اگر شامل بیش از یک عنصر باشند) برابر با حداقل فاصله جاکارد بین هر جفت عنصر، یکی از هر خوشه، است.

1.  **ادغام {f} و {h}**:
    *   فاصله: d(Cf, Ch) = **0**.
    *   خوشه جدید: **K1 = {f, h}**.
    *   تعداد خوشه‌ها: 7 ({a}, {b}, {c}, {d}, {e}, {g}, K1)

2.  **ادغام {b} و {d}**: (کوچکترین فاصله غیرصفر 0.333)
    *   فاصله: d(Cb, Cd) = **0.333**.
    *   خوشه جدید: **K2 = {b, d}**.
    *   تعداد خوشه‌ها: 6 ({a}, {c}, {e}, {g}, K1, K2)
    *   **بررسی فواصل جدید**:
        *   فاصله {g} به K2 = {b, d}: min(d(Cg,Cb), d(Cg,Cd)) = min(0.667, 0.333) = **0.333**.

3.  **ادغام {g} و K2 = {b, d}**: (کوچکترین فاصله 0.333)
    *   فاصله: d(Cg, K2) = **0.333**.
    *   خوشه جدید: **K3 = {b, d, g}**.
    *   تعداد خوشه‌ها: 5 ({a}, {c}, {e}, K1, K3)
    *   **بررسی فواصل جدید**:
        *   فاصله {a} به K3 = {b, d, g}: min(d(Ca,Cb), d(Ca,Cd), d(Ca,Cg)) = min(0.5, 0.667, 0.5) = **0.5**.
        *   فاصله {c} به K3 = {b, d, g}: min(d(Cc,Cb), d(Cc,Cd), d(Cc,Cg)) = min(0.5, 0.667, 1) = **0.5**.
        *   فاصله K1 = {f, h} به K3 = {b, d, g}: min(d(Cf,Cb), d(Cf,Cd), d(Cf,Cg), d(Ch,Cb), d(Ch,Cd), d(Ch,Cg)) = min(1, 0.667, 0.5, 1, 0.667, 0.5) = **0.5**.

4.  **ادغام {a} و K3 = {b, d, g}**: (چندین جفت با فاصله 0.5 وجود دارد، به صورت دلخواه {a} و K3 انتخاب می‌شود.)
    *   فاصله: d(Ca, K3) = **0.5**.
    *   خوشه جدید: **K4 = {a, b, d, g}**.
    *   تعداد خوشه‌ها: 4 ({c}, {e}, K1, K4)

**نتیجه بخش (الف): چهار خوشه نهایی عبارتند از:**
*   **خوشه 1: {f, h}**
*   **خوشه 2: {b, d, g}**
*   **خوشه 3: {a}**
*   **خوشه 4: {c}**
*   **خوشه 5: {e}**

**تجدیدنظر در خوشه‌بندی بخش (الف):**
به نظر می‌رسد انتخاب دلخواه در مرحله 4 باعث شد که به 5 خوشه برسیم. باید تا زمانی که دقیقاً 4 خوشه داریم، ادغام را ادامه دهیم. با توجه به اینکه در مرحله 4 چندین گزینه با فاصله 0.5 وجود داشت، یک ادغام دیگر باید انجام شود تا به 4 خوشه برسیم.
در مرحله 4، ما 5 خوشه داریم: {a}, {c}, {e}, K1={f,h}, K3={b,d,g}.
کوچکترین فاصله موجود در این مرحله 0.5 است. می‌توانیم یکی از ادغام‌های زیر را انجام دهیم تا به 4 خوشه برسیم:
*   {a} با K3
*   {c} با K3
*   K1 با K3

اگر {a} با K3 ادغام شود، خوشه‌های نهایی: **{a, b, d, g}, {c}, {e}, {f, h}** (این 4 خوشه نهایی هستند).

**نتیجه تصحیح‌شده بخش (الف):**
*   **C1 = {a, b, d, g}**
*   **C2 = {f, h}**
*   **C3 = {c}**
*   **C4 = {e}**

---

**بخش (ب): ساخت ماتریس جدید بر اساس خوشه‌های آیتم‌ها**

ماتریس جدید دارای ردیف‌های کاربران و ستون‌های خوشه‌های آیتم‌ها (C1، C2، C3، C4) خواهد بود. هر ورودی میانگین امتیازات غیرخالی کاربر برای آیتم‌های آن خوشه در ماتریس *اصلی* است.

ماتریس اصلی (شکل 9.8):
| آیتم | a | b | c | d | e | f | g | h |
|------|---|---|---|---|---|---|---|---|
| کاربر A | 4 | 5 |   | 5 | 1 |   | 3 | 2 |
| کاربر B |   | 3 | 4 | 3 | 1 | 2 | 1 |   |
| کاربر C | 2 |   | 1 | 3 |   | 4 | 5 | 3 |

**محاسبات برای ماتریس جدید:**

*   **کاربر A:**
    *   **C1 = {a, b, d, g}**: امتیازات A برای این آیتم‌ها: (a=4, b=5, d=5, g=3). میانگین: (4+5+5+3)/4 = 17/4 = **4.25**
    *   **C2 = {f, h}**: امتیازات A برای این آیتم‌ها: (h=2). میانگین: 2/1 = **2**
    *   **C3 = {c}**: امتیاز A برای c: خالی. ورودی **خالی** باقی می‌ماند.
    *   **C4 = {e}**: امتیاز A برای e: (e=1). میانگین: 1/1 = **1**

*   **کاربر B:**
    *   **C1 = {a, b, d, g}**: امتیازات B برای این آیتم‌ها: (b=3, d=3, g=1). (a خالی است). میانگین: (3+3+1)/3 = 7/3 = **2.33**
    *   **C2 = {f, h}**: امتیازات B برای این آیتم‌ها: (f=2). (h خالی است). میانگین: 2/1 = **2**
    *   **C3 = {c}**: امتیاز B برای c: (c=4). میانگین: 4/1 = **4**
    *   **C4 = {e}**: امتیاز B برای e: (e=1). میانگین: 1/1 = **1**

*   **کاربر C:**
    *   **C1 = {a, b, d, g}**: امتیازات C برای این آیتم‌ها: (a=2, d=3, g=5). (b خالی است). میانگین: (2+3+5)/3 = 10/3 = **3.33**
    *   **C2 = {f, h}**: امتیازات C برای این آیتم‌ها: (f=4, h=3). میانگین: (4+3)/2 = 7/2 = **3.5**
    *   **C3 = {c}**: امتیاز C برای c: (c=1). میانگین: 1/1 = **1**
    *   **C4 = {e}**: امتیاز C برای e: خالی. ورودی **خالی** باقی می‌ماند.

**ماتریس جدید (بخش ب):**
| کاربر | C1={a,b,d,g} | C2={f,h} | C3={c} | C4={e} |
|-------|---------------|----------|--------|--------|
| A     | 4.25          | 2        |        | 1      |
| B     | 2.33          | 2        | 4      | 1      |
| C     | 3.33          | 3.5      | 1      |        |

---

**بخش (ج): محاسبه فاصله کسینوسی بین هر جفت کاربر**

برای محاسبه فاصله کسینوسی، خانه‌های خالی را 0 در نظر می‌گیریم.
*   بردار کاربر A: **VA = [4.25, 2, 0, 1]**
*   بردار کاربر B: **VB = [2.33, 2, 4, 1]**
*   بردار کاربر C: **VC = [3.33, 3.5, 1, 0]**

**فرمول شباهت کسینوسی (sim):** (X . Y) / (||X|| ||Y||)
**فرمول فاصله کسینوسی (d):** 1 - sim(X, Y)

**1. فاصله کسینوسی بین کاربر A و B:**
*   VA . VB = (4.25 * 2.33) + (2 * 2) + (0 * 4) + (1 * 1) = 9.9025 + 4 + 0 + 1 = **14.9025**
*   ||VA|| = sqrt(4.25^2 + 2^2 + 0^2 + 1^2) = sqrt(18.0625 + 4 + 0 + 1) = sqrt(23.0625) = **4.8023**
*   ||VB|| = sqrt(2.33^2 + 2^2 + 4^2 + 1^2) = sqrt(5.4289 + 4 + 16 + 1) = sqrt(26.4289) = **5.1409**
*   sim(A, B) = 14.9025 / (4.8023 * 5.1409) = 14.9025 / 24.6983 = **0.6034**
*   **d(A, B) = 1 - 0.6034 = 0.3966**

**2. فاصله کسینوسی بین کاربر A و C:**
*   VA . VC = (4.25 * 3.33) + (2 * 3.5) + (0 * 1) + (1 * 0) = 14.1525 + 7 + 0 + 0 = **21.1525**
*   ||VA|| = **4.8023** (قبلاً محاسبه شده)
*   ||VC|| = sqrt(3.33^2 + 3.5^2 + 1^2 + 0^2) = sqrt(11.0889 + 12.25 + 1 + 0) = sqrt(24.3389) = **4.9334**
*   sim(A, C) = 21.1525 / (4.8023 * 4.9334) = 21.1525 / 23.6997 = **0.8925**
*   **d(A, C) = 1 - 0.8925 = 0.1075**

**3. فاصله کسینوسی بین کاربر B و C:**
*   VB . VC = (2.33 * 3.33) + (2 * 3.5) + (4 * 1) + (1 * 0) = 7.7589 + 7 + 4 + 0 = **18.7589**
*   ||VB|| = **5.1409** (قبلاً محاسبه شده)
*   ||VC|| = **4.9334** (قبلاً محاسبه شده)
*   sim(B, C) = 18.7589 / (5.1409 * 4.9334) = 18.7589 / 25.3664 = **0.7395**
*   **d(B, C) = 1 - 0.7395 = 0.2605**

**خلاصه فواصل کسینوسی بین کاربران:**
*   **d(A, B) = 0.3966**
*   **d(A, C) = 0.1075**
*   **d(B, C) = 0.2605**
---



در ادامه به ترجمه و حل تمرینات درخواست شده می‌پردازم:

---

### **تمرین‌های بخش 9.4**

**تمرین 9.4.1**
**ترجمه فارسی:**
با شروع از تجزیه ماتریس در شکل 9.10، می‌توانیم هر یک از 20 درایه ماتریس‌های U یا V را برای بهینه‌سازی انتخاب کنیم. این مرحله بهینه‌سازی اولیه را با فرض انتخاب:
(الف) `u32`
(ب) `v41`
انجام دهید.

**توضیح و پاسخ تمرین 9.4.1:**

در این تمرین، هدف بهینه‌سازی یک درایه واحد از ماتریس U یا V با استفاده از روش **نزول گرادیان (Gradient Descent)** است. این روش به دنبال یافتن مقداری برای درایه مورد نظر است که **خطای میانگین مربع ریشه (RMSE)** بین ماتریس اصلی M و حاصل‌ضرب U و V (یعنی UV) را به حداقل برساند. فرمول عمومی برای بهینه‌سازی درایه `u_rs` (در ماتریس U) یا `v_rs` (در ماتریس V) به شرح زیر است:

برای بهینه‌سازی `u_rs` (درایه در سطر r و ستون s ماتریس U):
`x = (∑_j v_sj * (m_rj - ∑_{k≠s} u_rk v_kj)) / (∑_j v_sj^2)`
که در آن:
*   `x` مقدار جدید `u_rs` است که به دنبال آن هستیم.
*   `r` و `s` به ترتیب شماره سطر و ستون در ماتریس U هستند.
*   `j` روی ستون‌هایی از M تکرار می‌شود که درایه `m_rj` (درایه مربوطه در M) خالی نباشد.
*   `m_rj` درایه مربوطه در ماتریس اصلی M است.
*   `v_sj` درایه‌های سطر `s` از ماتریس V هستند.
*   `u_rk` درایه‌های سطر `r` از ماتریس U (به جز `u_rs`) هستند.
*   `v_kj` درایه‌های ستون `j` از ماتریس V (به جز `v_sj`) هستند.
*   `∑_{k≠s}` به معنی جمع روی تمام مقادیر `k` بین 1 و `d` (تعداد مفهوم‌ها یا ابعاد کاهش‌یافته) به جز `k=s` است. (در این مثال `d=2` است زیرا U ماتریس 5x2 و V ماتریس 2x5 است).

**ماتریس‌های اولیه:**
از شکل 9.10، ماتریس‌های اولیه U و V که تمام درایه‌های آن‌ها 1 هستند، به شرح زیر است:
**U** =
```
[ 1 1 ]
[ 1 1 ]
[ 1 1 ]
[ 1 1 ]
[ 1 1 ]
```
**V** =
```
[ 1 1 1 1 1 ]
[ 1 1 1 1 1 ]
```
و ماتریس اصلی **M** از شکل 9.9 به شرح زیر است:
**M** =
```
[ 5  2  4  4  3 ]
[ 3  3  1  2  4 ]
[ 2 BLANK 1  4  2 ]
[ 2  5  4  1  5 ]
[ 4  4  5 BLANK 4 ]
```
(درایه‌های BLANK به معنی نامعلوم هستند و در محاسبات مربوط به RMSE نادیده گرفته می‌شوند).

**الف) بهینه‌سازی `u32`:**
درایه `u32` به معنی درایه در **سطر 3، ستون 2** ماتریس U است. بنابراین `r=3` و `s=2`.
فرمول بهینه‌سازی `u_rs` می‌شود:
`x = (∑_j v_2j * (m_3j - u_31 * v_1j)) / (∑_j v_2j^2)`
مقادیر درگیر:
*   `u_31` (درایه سطر 3، ستون 1 از U اولیه) = **1**.
*   `v_1j` (سطر 1 از V اولیه) = ``.
*   `v_2j` (سطر 2 از V اولیه) = ``.
*   `m_3j` (سطر 3 از M): `[2, BLANK, 1, 4, 2]`.
درایه‌های غیرخالی در `m_3j` برای `j = 1, 3, 4, 5` هستند.

**محاسبه مخرج کسر:**
`∑_j v_2j^2` بر روی ستون‌های غیرخالی M در سطر 3: `v_21^2 + v_23^2 + v_24^2 + v_25^2`
`= 1^2 + 1^2 + 1^2 + 1^2 = 1 + 1 + 1 + 1 = 4`

**محاسبه صورت کسر:**
`∑_j v_2j * (m_3j - u_31 * v_1j)`
`j=1`: `v_21 * (m_31 - u_31 * v_11) = 1 * (2 - 1 * 1) = 1 * (1) = 1`
`j=2`: `m_32` خالی است، بنابراین این ترم نادیده گرفته می‌شود.
`j=3`: `v_23 * (m_33 - u_31 * v_13) = 1 * (1 - 1 * 1) = 1 * (0) = 0`
`j=4`: `v_24 * (m_34 - u_31 * v_14) = 1 * (4 - 1 * 1) = 1 * (3) = 3`
`j=5`: `v_25 * (m_35 - u_31 * v_15) = 1 * (2 - 1 * 1) = 1 * (1) = 1`
**جمع صورت کسر:** `1 + 0 + 3 + 1 = 5`

**مقدار بهینه‌شده `u32`:** `x = 5 / 4 = 1.25`
**پاسخ:** مقدار بهینه‌شده `u32` برابر با **1.25** است.

---

**ب) بهینه‌سازی `v41`:**
**نکته مهم در مورد `v41`:** ماتریس V در مثال‌های کتاب (شکل 9.9 و 9.10) یک ماتریس 2×5 است، یعنی دارای 2 سطر و 5 ستون. در نتیجه درایه‌ای به نام `v41` (در سطر 4، ستون 1) در آن وجود ندارد. این یک ابهام در صورت سوال است. با توجه به متن تمرین که می‌گوید "هر یک از 20 درایه ماتریس‌های U یا V" (که 5x2=10 برای U و 2x5=10 برای V است و مجموعا 20 درایه می‌شود)، فرض می‌کنیم سوال به اشتباه نوشته شده و منظور **`v14`** (درایه سطر 1، ستون 4 از V) بوده است، زیرا `v14` یک درایه معتبر در ماتریس 2x5 V است.

با فرض اینکه منظور سوال `v14` (درایه در سطر 1، ستون 4 ماتریس V) است، بنابراین `r=1` (اشاره به ستون 1 از U و سطر 1 از V، یعنی مفهوم اول) و `s=4` (اشاره به ستون 4 از M و V، یعنی آیتم چهارم).

فرمول بهینه‌سازی `v_rs` (درایه در سطر r و ستون s ماتریس V):
`y = (∑_i u_ir * (m_is - ∑_{k≠r} u_ik v_ks)) / (∑_i u_ir^2)`
که در آن:
*   `y` مقدار جدید `v_rs` است که به دنبال آن هستیم.
*   `r` و `s` به ترتیب شماره سطر و ستون در ماتریس V (در اینجا `r=1, s=4`).
*   `i` روی سطر‌هایی از M تکرار می‌شود که درایه `m_is` (درایه مربوطه در M) خالی نباشد.
*   `u_ir` درایه‌های ستون `r` از ماتریس U هستند.
*   `m_is` درایه مربوطه در ماتریس اصلی M است.
*   `u_ik` درایه‌های سطر `i` از ماتریس U (به جز `u_ir`) هستند.
*   `v_ks` درایه‌های ستون `s` از ماتریس V (به جز `v_rs`) هستند.
*   `∑_{k≠r}` به معنی جمع روی تمام مقادیر `k` بین 1 و `d` (تعداد مفهوم‌ها، که اینجا `d=2` است) به جز `k=r` است.

مقادیر درگیر:
*   `u_i1` (ستون 1 از U اولیه) = ``.
*   `u_i2` (ستون 2 از U اولیه) = ``.
*   `v_24` (درایه سطر 2، ستون 4 از V اولیه) = **1**.
*   `m_i4` (ستون 4 از M): ``. (تمامی درایه‌ها غیرخالی هستند)
درایه‌های غیرخالی در `m_i4` برای `i = 1, 2, 3, 4, 5` هستند.

**محاسبه مخرج کسر:**
`∑_i u_i1^2` بر روی تمام سطرها (چون تمام درایه‌های `m_i4` غیرخالی هستند):
`= 1^2 + 1^2 + 1^2 + 1^2 + 1^2 = 1 + 1 + 1 + 1 + 1 = 5`

**محاسبه صورت کسر:**
`∑_i u_i1 * (m_i4 - u_i2 * v_24)`
`i=1`: `u_11 * (m_14 - u_12 * v_24) = 1 * (4 - 1 * 1) = 1 * (3) = 3`
`i=2`: `u_21 * (m_24 - u_22 * v_24) = 1 * (2 - 1 * 1) = 1 * (1) = 1`
`i=3`: `u_31 * (m_34 - u_32 * v_24) = 1 * (4 - 1 * 1) = 1 * (3) = 3`
`i=4`: `u_41 * (m_44 - u_42 * v_24) = 1 * (1 - 1 * 1) = 1 * (0) = 0`
`i=5`: `u_51 * (m_54 - u_52 * v_24) = 1 * (5 - 1 * 1) = 1 * (4) = 4`
**جمع صورت کسر:** `3 + 1 + 3 + 0 + 4 = 11`

**مقدار بهینه‌شده `v14` (با فرض `v41` typo):** `y = 11 / 5 = 2.2`
**پاسخ:** با فرض اینکه منظور سوال `v14` بوده است، مقدار بهینه‌شده آن برابر با **2.2** است.

---

**تمرین 9.4.2**
**ترجمه فارسی:**
اگر بخواهیم مانند شکل 9.10، تمام درایه‌های U و V را با یک مقدار ثابت یکسان مقداردهی اولیه کنیم، چه مقداری **خطای میانگین مربع ریشه (RMSE)** را برای ماتریس M مثال مورد بررسی (Running Example) به حداقل می‌رساند؟

**توضیح و پاسخ تمرین 9.4.2:**

در این تمرین، فرض می‌کنیم تمام درایه‌های ماتریس U و V برابر با یک مقدار ثابت `c` هستند.
ماتریس U ابعاد `n × d` دارد (در اینجا 5×2) و ماتریس V ابعاد `d × m` دارد (در اینجا 2×5). بنابراین `d=2`.
اگر تمام درایه‌های U و V برابر با `c` باشند، آنگاه هر درایه `p_ij` در ماتریس حاصل‌ضرب `P = UV` برابر خواهد بود با:
`p_ij = ∑_{k=1 to d} (u_ik * v_kj)`
`p_ij = ∑_{k=1 to 2} (c * c) = c^2 + c^2 = 2c^2`

پس، ماتریس `P` یک ماتریس 5×5 است که تمام درایه‌های آن `2c^2` هستند.
هدف ما حداقل کردن **مجموع مربعات خطاها (Sum of Squared Errors)** است. این مقدار برابر است با:
`E = ∑_i ∑_j (m_ij - p_ij)^2`
که در آن `i` و `j` روی تمام درایه‌های غیرخالی `m_ij` در ماتریس M تکرار می‌شوند.
`E = ∑_i ∑_j (m_ij - 2c^2)^2`

برای یافتن `c` که `E` را حداقل می‌کند، باید مشتق `E` نسبت به `c` را محاسبه کرده و آن را برابر با صفر قرار دهیم:
`dE/dc = ∑_i ∑_j 2 * (m_ij - 2c^2) * (-4c) = 0`
با تقسیم بر `(-8c)` (با فرض `c ≠ 0`):
`∑_i ∑_j (m_ij - 2c^2) = 0`
`∑_i ∑_j m_ij - ∑_i ∑_j 2c^2 = 0`

**جمع تمام درایه‌های غیرخالی ماتریس M:**
*   سطر 1: `5 + 2 + 4 + 4 + 3 = 18`
*   سطر 2: `3 + 3 + 1 + 2 + 4 = 13`
*   سطر 3: `2 + 1 + 4 + 2 = 9` (درایه خالی نادیده گرفته شد)
*   سطر 4: `2 + 5 + 4 + 1 + 5 = 17`
*   سطر 5: `4 + 4 + 5 + 4 = 17` (درایه خالی نادیده گرفته شد)
**مجموع کل درایه‌های غیرخالی M:** `18 + 13 + 9 + 17 + 17 = 74`

**تعداد درایه‌های غیرخالی M:** ماتریس M دارای 25 درایه است که 2 درایه آن خالی هستند. بنابراین تعداد درایه‌های غیرخالی `25 - 2 = 23` است.

اکنون معادله را حل می‌کنیم:
`74 - (23 * 2c^2) = 0`
`74 - 46c^2 = 0`
`46c^2 = 74`
`c^2 = 74 / 46 = 37 / 23`
`c = √(37 / 23)`

`c ≈ √1.60869565 ≈ 1.26834`

**پاسخ:** مقداری که تمام درایه‌های U و V باید به آن مقداردهی اولیه شوند تا RMSE به حداقل برسد، تقریباً برابر با **1.268** است.

---
